import openai
import shelve
from dotenv import load_dotenv
import os
import time
import traceback

# Charger la clÃ© API depuis .env
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("âš ï¸ OPEN_AI_API_KEY manquant dans .env")

openai.api_key = OPENAI_API_KEY

# Ton assistant existant (crÃ©Ã© une seule fois dans lâ€™interface OpenAI ou avec un autre script)
ASSISTANT_ID = "asst_QJuRk8I4LaZwcXh2FHVMnsTF"


# --------------------------------------------------------------
# Gestion des threads utilisateurs
# --------------------------------------------------------------
def check_if_thread_exists(wa_id):
    with shelve.open("threads_db") as threads_shelf:
        return threads_shelf.get(wa_id, None)

def store_thread(wa_id, thread_id):
    with shelve.open("threads_db", writeback=True) as threads_shelf:
        threads_shelf[wa_id] = thread_id


# --------------------------------------------------------------
# GÃ©nÃ©rer une rÃ©ponse
# --------------------------------------------------------------
def generate_response(message_body, wa_id, name):
    try:
        # VÃ©rifier si un thread existe dÃ©jÃ 
        thread_id = check_if_thread_exists(wa_id)

        if thread_id is None:
            print(f"ğŸ†• CrÃ©ation dâ€™un nouveau thread pour {name} ({wa_id})")
            thread = openai.beta.threads.create()
            store_thread(wa_id, thread.id)
            thread_id = thread.id
        else:
            print(f"ğŸ“‚ RÃ©cupÃ©ration du thread existant pour {name} ({wa_id})")
            thread = openai.beta.threads.retrieve(thread_id)

        # Ajouter le message utilisateur
        openai.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=message_body,
        )

        # ExÃ©cuter lâ€™assistant
        return run_assistant(thread)

    except Exception as e:
        print("ğŸ’¥ Erreur dans generate_response :", e)
        traceback.print_exc()
        return "DÃ©solÃ©, je rencontre un problÃ¨me technique."


# --------------------------------------------------------------
# Lancer lâ€™assistant
# --------------------------------------------------------------
def run_assistant(thread):
    try:
        run = openai.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=ASSISTANT_ID,
        )

        # Attendre la fin du traitement
        while run.status != "completed":
            time.sleep(0.5)
            run = openai.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)

        # RÃ©cupÃ©rer la derniÃ¨re rÃ©ponse
        messages = openai.beta.threads.messages.list(thread_id=thread.id)
        return messages.data[0].content[0].text.value

    except Exception as e:
        print("ğŸ’¥ Erreur dans run_assistant :", e)
        traceback.print_exc()
        return "Je n'ai pas pu traiter la demande."


# --------------------------------------------------------------
# Test hors webhook
# --------------------------------------------------------------
if __name__ == "__main__":
    print(generate_response("What's the check in time?", "123", "John"))
    print(generate_response("What's the pin for the lockbox?", "456", "Sarah"))
    print(generate_response("What was my previous question?", "123", "John"))
